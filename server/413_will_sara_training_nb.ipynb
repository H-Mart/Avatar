{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9ee8de-4bea-4af0-951e-b1fa8d84dba6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import from GCS with Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19612a18-8450-4a2e-a3d1-716f34287193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8331a42-b33c-4243-aea2-667c6b12be24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "  \n",
    "# create an Empty DataFrame object\n",
    "df = pd.DataFrame()\n",
    "temp_df = pd.DataFrame()\n",
    "\n",
    "labels = ['backward', 'forward',\n",
    "          'land', 'left', 'right', 'takeoff']\n",
    "\n",
    "for label in labels:\n",
    "    temp_df = pd.read_csv(f\"data/{label}/1.csv\", sep=',', comment='%')\n",
    "    df = pd.concat([df, temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b56afb-10db-4d55-b87b-dd66dda3791d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "col = []\n",
    "for x in range (0, 32):\n",
    "    x = f'_c{x}'\n",
    "    col.append(x)\n",
    "df = pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f068b2-d1fc-4e22-bb82-2804e8a4bfc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import From GCS with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466bb42a-6050-48db-87b5-66dc53071214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install delta-spark==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06adaf48-9300-42a5-8b03-63cfe328aa52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/14 15:39:50 WARN Utils: Your hostname, Henry-Desktop resolves to a loopback address: 127.0.1.1; using 172.20.208.84 instead (on interface eth0)\n",
      "24/02/14 15:39:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/home/henry/anaconda3/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/henry/.ivy2/cache\n",
      "The jars for the packages stored in: /home/henry/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-5a754d00-fcfc-46b8-a9bd-dadbaf30c42f;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.3.0 in central\n",
      "\tfound io.delta#delta-storage;2.3.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      ":: resolution report :: resolve 67ms :: artifacts dl 2ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.3.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.3.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-5a754d00-fcfc-46b8-a9bd-dadbaf30c42f\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/14 15:39:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from delta import *\n",
    "from pyspark.sql.functions import lit\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "    .config(\"spark.executor.memory\", \"12g\")\\\n",
    "    .config(\"spark.driver.memory\", \"12g\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594266fb-44a5-4226-80e3-9dfebf9485d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Writing to Delta lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5c8c3-6d2d-463a-ad72-c49ca9cf0565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "takeoff = spark.read.options(delimiter='\\t').csv(\"data/takeoff\", inferSchema='true')\n",
    "landdf = spark.read.options(delimiter='\\t').csv(\"data/land\", inferSchema='true')\n",
    "leftdf = spark.read.options(delimiter='\\t').csv(\"data/left\", inferSchema='true')\n",
    "rightdf = spark.read.options(delimiter='\\t').csv(\"data/right\", inferSchema='true')\n",
    "forward = spark.read.options(delimiter='\\t').csv(\"data/forward\", inferSchema='true')\n",
    "backward = spark.read.options(delimiter='\\t').csv(\"data/backward\", inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d71d0c-fc09-451f-b156-77cfe425f477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "takeoff = takeoff.withColumn(\"label\", lit(\"takeoff\"))\n",
    "landdf = landdf.withColumn(\"label\", lit(\"land\"))\n",
    "leftdf = leftdf.withColumn(\"label\", lit(\"left\"))\n",
    "rightdf = rightdf.withColumn(\"label\", lit(\"right\"))\n",
    "forward = forward.withColumn(\"label\", lit(\"forward\"))\n",
    "backward = backward.withColumn(\"label\", lit(\"backward\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2649fb-dd8e-40ac-9274-ffd9f52ce77b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = takeoff.union(landdf)\n",
    "df = df.union(leftdf)\n",
    "df = df.union(rightdf)\n",
    "df = df.union(forward)\n",
    "df = df.union(backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc954bb-be57-402f-87bc-225fc329f268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.write \\\n",
    "  .format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save(\"deltalake-table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c31d12e-e6d5-4e62-81aa-0858828092c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = spark.read.format(\"delta\").load(\"deltalake-table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a783e9-f183-4fbb-b630-35e133eaec40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Split into Test Train and Convert to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814370c3-e5ea-4f1c-8322-02e710f7f93d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/14 15:40:07 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pdf = df1.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce22d3da-5a3e-410b-98d2-01659a138eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sample Index, EXG Channel 0, EXG Channel 1, EX...</td>\n",
       "      <td>forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0,9339.922289839064,40817.81695101463,-56907...</td>\n",
       "      <td>forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210.0,9383.932874671564,40857.536000911714,-56...</td>\n",
       "      <td>forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212.0,9356.596691202723,40829.70807906486,-568...</td>\n",
       "      <td>forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>214.0,9377.830848435266,40858.07244277864,-569...</td>\n",
       "      <td>forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>216.0,9342.828016618254,40830.35627965407,-569...</td>\n",
       "      <td>forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>218.0,9357.42370574757,40845.82368681714,-5691...</td>\n",
       "      <td>forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>220.0,9331.56273741278,40818.86748300403,-5690...</td>\n",
       "      <td>forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>222.0,9349.84646437722,40841.263930948255,-569...</td>\n",
       "      <td>forward</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 _c0    label\n",
       "0  Sample Index, EXG Channel 0, EXG Channel 1, EX...  forward\n",
       "1  0.0,9339.922289839064,40817.81695101463,-56907...  forward\n",
       "2  210.0,9383.932874671564,40857.536000911714,-56...  forward\n",
       "3  212.0,9356.596691202723,40829.70807906486,-568...  forward\n",
       "4  214.0,9377.830848435266,40858.07244277864,-569...  forward\n",
       "5  216.0,9342.828016618254,40830.35627965407,-569...  forward\n",
       "6  218.0,9357.42370574757,40845.82368681714,-5691...  forward\n",
       "7  220.0,9331.56273741278,40818.86748300403,-5690...  forward\n",
       "8  222.0,9349.84646437722,40841.263930948255,-569...  forward"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f727cfe-e38b-480c-bd97-71ad60ffe9c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(pdf, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6639e378-d7cf-4973-aef3-77165e17f34b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1755196</th>\n",
       "      <td>138.0,29816.131867901317,51920.26369813248,419...</td>\n",
       "      <td>backward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762041</th>\n",
       "      <td>200.0,13217.659380156922,18098.0733749954,3224...</td>\n",
       "      <td>backward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564557</th>\n",
       "      <td>146.0,41083.26626816586,2004.638553218669,3191...</td>\n",
       "      <td>land</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       _c0     label\n",
       "1755196  138.0,29816.131867901317,51920.26369813248,419...  backward\n",
       "1762041  200.0,13217.659380156922,18098.0733749954,3224...  backward\n",
       "1564557  146.0,41083.26626816586,2004.638553218669,3191...      land"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45b39ff-2158-46a4-a7bc-b22196ee21e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train Model with Spark to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9911814-d0bc-47f9-a421-eb4cfdc0fa67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:40:55.329029: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-14 15:40:55.355551: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-14 15:40:55.355585: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-14 15:40:55.356725: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-14 15:40:55.360908: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-14 15:40:55.861170: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0afb227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_decision_forests\n",
      "  Downloading tensorflow_decision_forests-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: numpy in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow_decision_forests) (1.24.3)\n",
      "Requirement already satisfied: pandas in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow_decision_forests) (2.0.3)\n",
      "Requirement already satisfied: tensorflow~=2.15.0 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow_decision_forests) (2.15.0.post1)\n",
      "Requirement already satisfied: six in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow_decision_forests) (1.16.0)\n",
      "Requirement already satisfied: absl-py in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow_decision_forests) (2.1.0)\n",
      "Requirement already satisfied: wheel in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow_decision_forests) (0.38.4)\n",
      "Requirement already satisfied: wurlitzer in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow_decision_forests) (3.0.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (4.25.2)\n",
      "Requirement already satisfied: setuptools in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (68.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.60.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/henry/anaconda3/lib/python3.11/site-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/henry/anaconda3/lib/python3.11/site-packages (from pandas->tensorflow_decision_forests) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/henry/anaconda3/lib/python3.11/site-packages (from pandas->tensorflow_decision_forests) (2023.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/henry/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/henry/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/henry/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/henry/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/henry/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/henry/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/henry/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/henry/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/henry/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/henry/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/henry/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/henry/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.2.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tensorflow_decision_forests-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorflow_decision_forests\n",
      "Successfully installed tensorflow_decision_forests-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_decision_forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaad5d38-3486-4960-be9f-f11a672c7686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 15:41:58.332815: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-14 15:41:58.537015: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-14 15:41:58.537049: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-14 15:41:58.539213: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-14 15:41:58.539250: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-14 15:41:58.539268: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-14 15:41:58.750620: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-14 15:41:58.750744: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-14 15:41:58.750752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-14 15:41:58.750805: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-14 15:41:58.750876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9717 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "import pandas as pd\n",
    "\n",
    "# Load a dataset in a Pandas dataframe.\n",
    "\n",
    "# Convert the dataset into a TensorFlow dataset.\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train, label=\"label\")\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test, label=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b5792f5-4e0c-4387-b75b-347ac65f7734",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254159, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4504e0c-9cd6-442d-9557-ace0b75e1208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpatqcryi6 as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:04.424569. Found 2287430 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:16.429663\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-02-14 15:45:15.7326 CST kernel.cc:1233] Loading model from path /tmp/tmpatqcryi6/model/ with prefix 651c18a55875429d\n",
      "[INFO 24-02-14 15:45:15.7333 CST decision_forest.cc:660] Model loaded with 300 root(s), 900 node(s), and 1 input feature(s).\n",
      "[INFO 24-02-14 15:45:15.7333 CST abstract_model.cc:1344] Engine \"RandomForestGeneric\" built\n",
      "[INFO 24-02-14 15:45:15.7333 CST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f29adfc2910>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest model.\n",
    "model = tfdf.keras.RandomForestModel()\n",
    "model.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d82efa6-bbcc-40ee-8644-ac57b1c7e48a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"random_forest_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1 (1.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 1 (1.00 Byte)\n",
      "_________________________________________________________________\n",
      "Type: \"RANDOM_FOREST\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (1):\n",
      "\tc0\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
      "    1. \"c0\"  1.000000 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1. \"c0\" 300.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1. \"c0\" 300.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1. \"c0\" 827.343943 \n",
      "\n",
      "\n",
      "\n",
      "Winner takes all: true\n",
      "Out-of-bag evaluation: accuracy:0.174613 logloss:29.7285\n",
      "Number of trees: 300\n",
      "Total number of nodes: 900\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 300 Average: 3 StdDev: 0\n",
      "Min: 3 Max: 3 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 3, 3] 300 100.00% 100.00% ##########\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 600 Average: 1 StdDev: 0\n",
      "Min: 1 Max: 1 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 1, 1] 600 100.00% 100.00% ##########\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 600 Average: 1.14372e+06 StdDev: 1.14193e+06\n",
      "Min: 1681 Max: 2285749 Ignored: 0\n",
      "----------------------------------------------\n",
      "[    1681,  115884) 300  50.00%  50.00% ##########\n",
      "[  115884,  230087)   0   0.00%  50.00%\n",
      "[  230087,  344291)   0   0.00%  50.00%\n",
      "[  344291,  458494)   0   0.00%  50.00%\n",
      "[  458494,  572698)   0   0.00%  50.00%\n",
      "[  572698,  686901)   0   0.00%  50.00%\n",
      "[  686901,  801105)   0   0.00%  50.00%\n",
      "[  801105,  915308)   0   0.00%  50.00%\n",
      "[  915308, 1.02951e+06)   0   0.00%  50.00%\n",
      "[ 1.02951e+06, 1.14372e+06)   0   0.00%  50.00%\n",
      "[ 1.14372e+06, 1.25792e+06)   0   0.00%  50.00%\n",
      "[ 1.25792e+06, 1.37212e+06)   0   0.00%  50.00%\n",
      "[ 1.37212e+06, 1.48632e+06)   0   0.00%  50.00%\n",
      "[ 1.48632e+06, 1.60053e+06)   0   0.00%  50.00%\n",
      "[ 1.60053e+06, 1.71473e+06)   0   0.00%  50.00%\n",
      "[ 1.71473e+06, 1.82894e+06)   0   0.00%  50.00%\n",
      "[ 1.82894e+06, 1.94314e+06)   0   0.00%  50.00%\n",
      "[ 1.94314e+06, 2.05734e+06)   0   0.00%  50.00%\n",
      "[ 2.05734e+06, 2.17155e+06)   0   0.00%  50.00%\n",
      "[ 2.17155e+06, 2.28575e+06] 300  50.00% 100.00% ##########\n",
      "\n",
      "Attribute in nodes:\n",
      "\t300 : c0 [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t300 : c0 [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t300 : c0 [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t300 : c0 [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t300 : c0 [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t300 : c0 [CATEGORICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t300 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t300 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t300 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t300 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t300 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t300 : ContainsBitmapCondition\n",
      "Node format: NOT_SET\n",
      "\n",
      "Training OOB:\n",
      "\ttrees: 1, Out-of-bag evaluation: accuracy:0.174312 logloss:29.7608\n",
      "\ttrees: 11, Out-of-bag evaluation: accuracy:0.174582 logloss:29.7415\n",
      "\ttrees: 21, Out-of-bag evaluation: accuracy:0.174602 logloss:29.7355\n",
      "\ttrees: 31, Out-of-bag evaluation: accuracy:0.17461 logloss:29.7332\n",
      "\ttrees: 41, Out-of-bag evaluation: accuracy:0.174611 logloss:29.7311\n",
      "\ttrees: 51, Out-of-bag evaluation: accuracy:0.174604 logloss:29.7305\n",
      "\ttrees: 61, Out-of-bag evaluation: accuracy:0.174609 logloss:29.7303\n",
      "\ttrees: 71, Out-of-bag evaluation: accuracy:0.174609 logloss:29.7295\n",
      "\ttrees: 81, Out-of-bag evaluation: accuracy:0.174611 logloss:29.7292\n",
      "\ttrees: 91, Out-of-bag evaluation: accuracy:0.174612 logloss:29.7289\n",
      "\ttrees: 101, Out-of-bag evaluation: accuracy:0.174611 logloss:29.7288\n",
      "\ttrees: 111, Out-of-bag evaluation: accuracy:0.17461 logloss:29.7287\n",
      "\ttrees: 121, Out-of-bag evaluation: accuracy:0.174611 logloss:29.7286\n",
      "\ttrees: 131, Out-of-bag evaluation: accuracy:0.174612 logloss:29.7286\n",
      "\ttrees: 141, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7286\n",
      "\ttrees: 151, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7286\n",
      "\ttrees: 161, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7286\n",
      "\ttrees: 171, Out-of-bag evaluation: accuracy:0.174612 logloss:29.7285\n",
      "\ttrees: 181, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7285\n",
      "\ttrees: 191, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7285\n",
      "\ttrees: 201, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7285\n",
      "\ttrees: 211, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7285\n",
      "\ttrees: 221, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7285\n",
      "\ttrees: 231, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7285\n",
      "\ttrees: 241, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7285\n",
      "\ttrees: 251, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7285\n",
      "\ttrees: 261, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7285\n",
      "\ttrees: 271, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7285\n",
      "\ttrees: 281, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7285\n",
      "\ttrees: 291, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7285\n",
      "\ttrees: 300, Out-of-bag evaluation: accuracy:0.174613 logloss:29.7285\n",
      "\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: /home/henry/Avatar/server/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/henry/Avatar/server/model/assets\n"
     ]
    }
   ],
   "source": [
    "# Summary of the model structure.\n",
    "model.summary()\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(test_ds)\n",
    "\n",
    "# Export the model to a SavedModel.\n",
    "model.save(\"/home/henry/Avatar/server/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf29f9c2-d44e-4a1d-8fec-db819136fb4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test Spark Pandas Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497328dd-df88-4771-b837-d60b6820a771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testdf = spark.read.options(delimiter='\\t').csv(\"gs://bci_bucket/data/takeoff/BrainFlow-RAW_Recordings_takeoff_4.csv\", inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab68edbe-897e-435e-b4dd-512064c50b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf = testdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e5e4fc-9555-49ab-b835-80be5838430b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b844dbf-14e8-4f1f-8ea7-cf7d7d544ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip show tensorflow_decision_forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b973b-9726-4f86-8068-b0bc9f49b20c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "import tensorflow_decision_forests as tfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059e5b4d-1d53-4898-b9ca-b1157e21026b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(\"/home/jovyan/notebooks/modelv3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d22789-6e26-4a91-8cad-0a83e7631b5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idk = tfdf.keras.pd_dataframe_to_tf_dataset(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b41d0-3c1e-49ed-91d2-afeee12dee50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177d5f9-7292-48bd-846f-e0ea9c4f9ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = ['backward', 'down', 'forward',\n",
    "          'land', 'left', 'right', 'takeoff', 'up']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c5bf57-cf3b-4090-867f-855c606b4f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = np.argmax(prediction, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc58ec-4844-4ed0-b311-a754d01f9402",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = labels[prediction[0]]\n",
    "predicted_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
