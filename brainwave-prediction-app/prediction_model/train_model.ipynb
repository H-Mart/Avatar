{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40d7671c6e276ec5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.data_processing import load_data, data_preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from src.data_processing.config import processed_dir_path\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from functools import partial\n",
    "\n",
    "start = time()\n",
    "\n",
    "df = load_data.load_csvs(processed_dir_path)\n",
    "print(f\"Time to load data: {time() - start}\")\n",
    "df.sort_values(by=['session', 'trial', ' Timestamp'], inplace=True)\n",
    "cols = [str(x) for x in df.columns if x.startswith(' EXG')]\n",
    "labels = ['left', 'right', 'takeoff', 'land', 'forward', 'backward']"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_sample_number = df.groupby('trial', sort=False).size().max()\n",
    "max_sample_number"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b12f408dffe0c174",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_trials = df.trial.nunique()\n",
    "num_trials"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb5eb5436f84099c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "110ea90190059456",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def filter_trials(dataframe, sampling_rate=125, low_cutoff=.5, high_cutoff=50):\n",
    "    dfs = []\n",
    "    for trial, group in dataframe.groupby('trial', sort=False, as_index=False):\n",
    "        filtered_cols = data_preprocessing.apply_filters(group[cols], sampling_rate, low_cutoff, high_cutoff)\n",
    "        group[cols] = filtered_cols\n",
    "        group['trial'] = trial\n",
    "        dfs.append(group)\n",
    "    new_df = pd.concat(dfs, ignore_index=True)\n",
    "    new_df.sort_values(by=['session', 'trial', ' Timestamp'], inplace=True)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def remove_outliers(dataframe):\n",
    "    channels = dataframe[cols].to_numpy()\n",
    "    channels_med = np.median(np.abs(channels), axis=0)\n",
    "    mad = stats.median_abs_deviation(channels, axis=0, center=lambda *_, **__: channels_med)\n",
    "    m_scores = np.abs((channels - channels_med) / mad)\n",
    "\n",
    "    max_ok_score = 4\n",
    "    ok_scores = m_scores < max_ok_score\n",
    "    channels[~ok_scores] = 0\n",
    "\n",
    "    dataframe[cols] = channels\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64ea4640b77b3774",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "n = f_df[cols].to_numpy()\n",
    "n_med = np.median(np.abs(n), axis=0)\n",
    "mad = stats.median_abs_deviation(n, axis=0, center=lambda *_, **__: n_med)\n",
    "m_scores = np.abs((n - n_med) / mad)\n",
    "\n",
    "max_ok_score = 4\n",
    "ok_scores = m_scores < max_ok_score\n",
    "n[~ok_scores] = 0\n",
    "\n",
    "f_df[cols] = n\n",
    "f_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3acccc5d9dde0a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dfg1 = f_df[f_df.trial == 1000].groupby('trial', sort=False)[cols]\n",
    "axes1 = dfg1.plot(subplots=True, figsize=(10, 10))\n",
    "# \n",
    "\n",
    "# print(f_df.describe())\n",
    "# print(df2.describe())\n",
    "\n",
    "# print()\n",
    "for ax in axes1:\n",
    "    for a in ax:\n",
    "        a.set_ylim(-50, 50)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69703b346b943aed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.fft import rfft, rfftfreq, next_fast_len\n",
    "\n",
    "n = next_fast_len(max_sample_number)\n",
    "num_freqs = n // 2 + 1\n",
    "freq_matrix = np.zeros((num_freqs, len(cols), num_trials))\n",
    "\n",
    "f_df = filter_trials(df)\n",
    "\n",
    "channels = f_df[cols].to_numpy()\n",
    "channels_med = np.median(np.abs(channels), axis=0)\n",
    "mad = stats.median_abs_deviation(channels, axis=0, center=lambda *_, **__: channels_med)\n",
    "m_scores = np.abs((channels - channels_med) / mad)\n",
    "\n",
    "max_ok_score = 4\n",
    "ok_scores = m_scores < max_ok_score\n",
    "channels[~ok_scores] = 0\n",
    "\n",
    "f_df[cols] = channels\n",
    "\n",
    "label_session_map = np.zeros((num_trials, 2), dtype=object)\n",
    "\n",
    "for i, (trial, group) in enumerate(f_df.groupby('trial', sort=False)):\n",
    "    label_session_map[i, :] = group['label'].iloc[0], group['session'].iloc[0]\n",
    "    trial_data = group[cols].to_numpy(copy=True)\n",
    "    signal_fft = rfft(trial_data, n, axis=0)\n",
    "    freq_matrix[:, :, i] = np.abs(signal_fft)\n",
    "\n",
    "signal_freq = rfftfreq(n, d=1 / 125)\n",
    "# mean_freq_matrix = np.mean(freq_matrix, axis=2)\n",
    "# mean_freq_matrix\n",
    "freq_matrix[:, :, 0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5783e6ffc5e611fc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.signal import correlate\n",
    "\n",
    "mean_freq_by_label = {}\n",
    "\n",
    "for label in labels:\n",
    "    mean_freq_by_label[label] = np.mean(freq_matrix[:, :, label_session_map[:, 0] == label], axis=2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 6, figsize=(20, 10))\n",
    "for i, (label, label_mean_freq_matrix) in enumerate(mean_freq_by_label.items()):\n",
    "    self_correlation = correlate(label_mean_freq_matrix[:, 0], label_mean_freq_matrix[:, 0], mode='same')\n",
    "    axes[i].plot(signal_freq, self_correlation, label=label)\n",
    "    # axes[i].set_title(f'Channel {j}')\n",
    "# plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a16c13d5b5c8c15",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(freq_matrix.shape[1], 1, figsize=(20, 20))\n",
    "for j in range(freq_matrix.shape[1]):\n",
    "    for label, label_mean_freq_matrix in mean_freq_by_label.items():\n",
    "        axes[j].plot(signal_freq, label_mean_freq_matrix[:, j], label=label)\n",
    "        axes[j].set_title(f'Channel {j}')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7d68b5de6b21735",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training\n",
    "Testing GroupKFold first\n",
    "Raw channel data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "553c29fbcc08cdc8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def split_on_trial():\n",
    "    saved_trials = pd.DataFrame(columns=['label', 'trial'])\n",
    "    for label, group in df.groupby('label', sort=False):\n",
    "        # select 10% of the trials to take out of the training set\n",
    "        label_trials_to_take_out = pd.DataFrame(columns=['label', 'trial'])\n",
    "        label_trials_to_take_out['trial'] = group.trial.drop_duplicates().sample(frac=0.1, random_state=42)\n",
    "        label_trials_to_take_out['label'] = label\n",
    "        saved_trials = pd.concat([saved_trials, label_trials_to_take_out])\n",
    "    return saved_trials\n",
    "\n",
    "\n",
    "def split_on_session():\n",
    "    saved_trials = pd.DataFrame(columns=['label', 'trial'])\n",
    "    for label, group in df.groupby('label', sort=False):\n",
    "        # select 10% of the trials to take out of the training set\n",
    "        sessions_to_take_out = group.session.drop_duplicates().sample(frac=0.1, random_state=42)\n",
    "        session_trials_to_take_out = pd.DataFrame(columns=['label', 'trial'])\n",
    "        session_trials_to_take_out['trial'] = group[group.session.isin(sessions_to_take_out)].trial.drop_duplicates()\n",
    "        session_trials_to_take_out['label'] = label\n",
    "        saved_trials = pd.concat([saved_trials, session_trials_to_take_out])\n",
    "    return saved_trials\n",
    "\n",
    "\n",
    "def train_test_split(dataframe, split_on: str = 'trial'):\n",
    "    if split_on == 'trial':\n",
    "        saved_trials = split_on_trial()\n",
    "    elif split_on == 'session':\n",
    "        saved_trials = split_on_session()\n",
    "    else:\n",
    "        raise ValueError('split_on must be either \"trial\" or \"session\"')\n",
    "\n",
    "    training_set = dataframe[~dataframe.trial.isin(saved_trials.trial)]\n",
    "    testing_set = dataframe[dataframe.trial.isin(saved_trials.trial)]\n",
    "\n",
    "    return training_set, testing_set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39b992449131989d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.fft import rfft, rfftfreq, next_fast_len\n",
    "\n",
    "\n",
    "def make_freq_df(dataframe, cols):\n",
    "    max_trial_len = dataframe.groupby('trial', sort=False).size().max()\n",
    "    n = next_fast_len(max_trial_len)\n",
    "\n",
    "    signal_freq = rfftfreq(n, d=1 / 125)\n",
    "    trial_dfs = []\n",
    "    for trial, group in dataframe.groupby('trial', sort=False):\n",
    "        trial_df = pd.DataFrame()\n",
    "        trial_data = group[cols].to_numpy(copy=True)\n",
    "        signal_fft = rfft(trial_data, n, axis=0)\n",
    "        trial_df['freq'] = signal_freq\n",
    "        trial_df[cols] = np.abs(signal_fft)\n",
    "        trial_df['trial'] = trial\n",
    "        trial_df['label'] = group['label'].iloc[0]\n",
    "        trial_df['session'] = group['session'].iloc[0]\n",
    "        trial_dfs.append(trial_df)\n",
    "    freq_df = pd.concat(trial_dfs, ignore_index=True)\n",
    "    return freq_df\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93418fc7274d4876",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearnex.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, cross_validate\n",
    "from mlxtend.evaluate import GroupTimeSeriesSplit\n",
    "\n",
    "df.sort_values(by=['session', 'trial', ' Timestamp'], inplace=True)\n",
    "\n",
    "filtered_df = df\n",
    "# filtered_df = filter_trials(df)\n",
    "# filtered_df = remove_outliers(filtered_df)\n",
    "# filtered_df = make_freq_df(filtered_df, cols)\n",
    "\n",
    "training_set, testing_set = train_test_split(filtered_df, split_on='session')\n",
    "\n",
    "X = training_set[cols].to_numpy().astype(np.float64)\n",
    "y = training_set['label'].map(lambda x: labels.index(x)).to_numpy()\n",
    "groups = training_set['session'].to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7305dadf86eaee88",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# gkf = GroupKFold(n_splits=5)\n",
    "gkf = GroupTimeSeriesSplit(test_size=20, n_splits=10)\n",
    "clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "scoring = {'accuracy': 'accuracy'}\n",
    "cv_results = cross_validate(clf, X, y, groups=groups, cv=gkf, scoring=scoring, return_train_score=True, verbose=2,\n",
    "                            n_jobs=-1, return_estimator=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f5d0aa55a18d3ae",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cv_results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28c4ab8fcbf6fc03",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "estimators = cv_results['estimator']\n",
    "test_X = testing_set[cols].to_numpy().astype(np.float64)\n",
    "test_y = testing_set['label'].map(lambda x: labels.index(x)).to_numpy()\n",
    "\n",
    "y_pred = np.zeros((test_X.shape[0], len(estimators)))\n",
    "accuracy = np.zeros(len(estimators))\n",
    "for i, estimator in enumerate(estimators):\n",
    "    y_pred[:, i] = estimator.predict(test_X)\n",
    "    accuracy[i] = accuracy_score(test_y, y_pred[:, i])\n",
    "\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "322ef379c56c111f",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
